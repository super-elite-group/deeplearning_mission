{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkh2qVXxL3Bw"
      },
      "source": [
        "# 1. 데이터 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WWUtmkOxLovz"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "import torchvision\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "download_root = './MNIST_DATASET'\n",
        "\n",
        "mnist_transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(download_root, transform=mnist_transform, train=True, download=False)\n",
        "test_dataset = torchvision.datasets.MNIST(download_root, transform=mnist_transform, train=False, download=False)\n",
        "\n",
        "total_size = len(train_dataset)\n",
        "train_num, valid_num = int(total_size * 0.8), int(total_size * 0.2)\n",
        "train_dataset,valid_dataset = torch.utils.data.random_split(train_dataset, [train_num, valid_num])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArpCSOs3Wpbf",
        "outputId": "84a5af4d-a01e-4e56-db7a-ec42fdfa679d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "for data, label in train_dataloader:\n",
        "    print(data.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixyFM52zRKhG"
      },
      "source": [
        "# 2.모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1w_-DVA5RNmv"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import LightningModule, Trainer\n",
        "import torch.optim as optim\n",
        "import torchmetrics\n",
        "import torch.nn as nn\n",
        "\n",
        "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTMClassifier(LightningModule):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, lr):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_classes = num_classes\n",
        "        self.learning_rate = lr\n",
        "        \n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes = num_classes)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        INPUT\n",
        "            x : [32, 1, 28, 28]\n",
        "        OUTPUT\n",
        "            out : [32, 10]\n",
        "        '''\n",
        "        x = x.squeeze()\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "\n",
        "        return out\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr = self.learning_rate)\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "\n",
        "        loss = self.criterion(y_hat, y)\n",
        "\n",
        "        _, predict = torch.max(y_hat, dim = 1)\n",
        "        acc = self.accuracy(predict, y)\n",
        "\n",
        "        self.log(f\"train_loss\", loss, on_step = False, on_epoch = True, logger = True)\n",
        "        self.log(f\"train_acc\", acc, on_step = False, on_epoch = True, logger = True)\n",
        "        \n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "\n",
        "        loss = self.criterion(y_hat, y)\n",
        "\n",
        "        _, predict = torch.max(y_hat, dim = 1)\n",
        "        acc = self.accuracy(predict, y)\n",
        "\n",
        "        self.log(f\"valid_loss\", loss, on_step = False, on_epoch = True, logger = True)\n",
        "        self.log(f\"valid_acc\", acc, on_step = False, on_epoch = True, logger = True)\n",
        "        \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "\n",
        "        loss = self.criterion(y_hat, y)\n",
        "\n",
        "        _, predict = torch.max(y_hat, dim = 1)\n",
        "        acc = self.accuracy(predict, y)\n",
        "\n",
        "        self.log(f\"test_loss\", loss, on_step = False, on_epoch = True, logger = True)\n",
        "        self.log(f\"test_acc\", acc, on_step = False, on_epoch = True, logger = True)\n",
        "        \n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "\n",
        "        _, predict = torch.max(y_hat, dim = 1)\n",
        "\n",
        "        return predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u4C0ZsEWiXO"
      },
      "source": [
        "# 3. 모델 실행 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtjsgh2770\u001b[0m (\u001b[33mprefer_leee\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d784d68f6bd948508327e0ca9008345c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011277777777932999, max=1.0…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>.\\wandb\\run-20240626_231746-g5azscif</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prefer_leee/MNIST_LSTM/runs/g5azscif' target=\"_blank\">denim-silence-1</a></strong> to <a href='https://wandb.ai/prefer_leee/MNIST_LSTM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/prefer_leee/MNIST_LSTM' target=\"_blank\">https://wandb.ai/prefer_leee/MNIST_LSTM</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/prefer_leee/MNIST_LSTM/runs/g5azscif' target=\"_blank\">https://wandb.ai/prefer_leee/MNIST_LSTM/runs/g5azscif</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type               | Params | Mode \n",
            "---------------------------------------------------------\n",
            "0 | criterion | CrossEntropyLoss   | 0      | train\n",
            "1 | accuracy  | MulticlassAccuracy | 0      | train\n",
            "2 | lstm      | LSTM               | 212 K  | train\n",
            "3 | fc        | Linear             | 1.3 K  | train\n",
            "---------------------------------------------------------\n",
            "214 K     Trainable params\n",
            "0         Non-trainable params\n",
            "214 K     Total params\n",
            "0.857     Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "152ede24d0a44d899ed679c3699ffbda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tjsgh\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
            "c:\\Users\\tjsgh\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "709199d479c2413aa3a45d8812e719f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tjsgh\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b978e7cc540498fbd9fec6e77784a39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ffd726ea4124d4e80b9d0610461d53c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5224e6a92c6e4e4eaa274a3436116440",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "371f3f8feaf7484b9a94ece728a4e052",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22db4438e69d441ab4620a2babb4c2cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38fc90a6b9cd4addbe9881a50ef90bab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "c:\\Users\\tjsgh\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f56f4cfde3d94b94b78c08bbdd8a750c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10320000350475311    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2.304932117462158     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10320000350475311   \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2.304932117462158    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'test_loss': 2.304932117462158, 'test_acc': 0.10320000350475311}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LSTMClassifier(input_size = 28, hidden_size = 128, num_layers = 2, num_classes = 10, lr = 0.001)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor = 'valid_loss', mode = 'min', patience=5)\n",
        "lr_mointor = LearningRateMonitor(logging_interval = 'epoch')\n",
        "\n",
        "wandb_logger = WandbLogger(project = 'MNIST_LSTM')\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs = 100,\n",
        "    accelerator = 'auto',\n",
        "    callbacks = [early_stopping, lr_mointor],\n",
        "    logger = wandb_logger\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    valid_dataloader\n",
        ")\n",
        "\n",
        "trainer.test(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
