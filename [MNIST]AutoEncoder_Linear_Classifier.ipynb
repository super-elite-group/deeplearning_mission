{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import random\n",
    "\n",
    "download_root = './MNIST_DATASET'\n",
    "\n",
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(download_root, transform=mnist_transform, train=True, download=False)\n",
    "test_dataset = torchvision.datasets.MNIST(download_root, transform=mnist_transform, train=False, download=False) \n",
    "\n",
    "total_size = len(train_dataset)\n",
    "batch_size = 32\n",
    "batch_num = total_size // batch_size\n",
    "labeled_batch_idx = random.choices(range(batch_num), k = int(batch_num * 0.1))\n",
    "batch_idx = -1\n",
    "def collate_fn(batch):\n",
    "    global batch_idx\n",
    "    images, labels = zip(*batch)  # 배치 내 샘플을 이미지와 라벨로 분리\n",
    "\n",
    "    batch_idx += 1\n",
    "    if batch_idx in labeled_batch_idx:\n",
    "        labels = torch.tensor(labels)  # 라벨 리스트를 배치 형태로 쌓음\n",
    "    else:\n",
    "        labels = None\n",
    "\n",
    "    images = torch.stack(images, dim=0)  # 이미지 리스트를 배치 형태로 쌓음\n",
    "    return images, labels\n",
    "\n",
    "valid_indices = random.sample(list(range(total_size)), int(total_size * 0.1))\n",
    "\n",
    "train_dataloader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle= True)\n",
    "shuffled_train_dataloader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle= True, collate_fn = collate_fn)\n",
    "valid_dataloader = DataLoader(dataset = train_dataset, batch_size = batch_size, sampler = SubsetRandomSampler(valid_indices))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from  pytorch_lightning import LightningModule \n",
    "import torch.optim as optim\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderLinear(LightningModule):\n",
    "    def __init__(self, symetric_dimensions, lr):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lr = lr\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "        encoder_layer = []\n",
    "        decoder_layer = []\n",
    "\n",
    "        self.active = nn.ReLU()\n",
    "        self.sig_act = nn.Sigmoid()\n",
    "        \n",
    "        for idx, dim in enumerate(symetric_dimensions[1:]):\n",
    "            input = symetric_dimensions[idx]\n",
    "            fc_layer = nn.Linear(input, dim)\n",
    "            encoder_layer.append(fc_layer)\n",
    "            encoder_layer.append(self.active)\n",
    "\n",
    "        reverse_symetric_dimensions = symetric_dimensions[::-1]\n",
    "        for idx, dim in enumerate(reverse_symetric_dimensions[1:]):\n",
    "            input = reverse_symetric_dimensions[idx]\n",
    "            fc_layer = nn.Linear(input, dim)\n",
    "            decoder_layer.append(fc_layer)\n",
    "\n",
    "            # 마지막 레이어는 sigmoid(0~1 값으로 출력하기 위해서)\n",
    "            if idx == len(reverse_symetric_dimensions) - 2:\n",
    "                decoder_layer.append(self.sig_act)\n",
    "            else:\n",
    "                decoder_layer.append(self.active)\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_layer)\n",
    "        self.decoder = nn.Sequential(*decoder_layer)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        '''\n",
    "        INPUT\n",
    "            x : [batch_size, 1, 28, 28]\n",
    "        OUTPUT\n",
    "            out : [batch_size, 28 * 28]\n",
    "        '''\n",
    "        x = x.view(x.size(0), -1) # [batch_size, 28 * 28]\n",
    "        out = self.encoder(x)\n",
    "        out = self.decoder(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr = self.lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        data, label = batch\n",
    "        \n",
    "        y = data.view(data.size(0), -1)\n",
    "        y_hat = self(data)\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.log(f\"train_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        data, label = batch\n",
    "        \n",
    "        y = data.view(data.size(0), -1)\n",
    "        y_hat = self(data)\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.log(f\"valid_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        data, label = batch\n",
    "        \n",
    "        y = data.view(data.size(0), -1)\n",
    "        y_hat = self(data)\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.log(f\"test_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, x):\n",
    "        x = x.view(x.size(0), -1) \n",
    "        latent_vec = self.encoder(x)\n",
    "\n",
    "        return latent_vec # [batch_size, 28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | criterion | MSELoss    | 0      | train\n",
      "1 | active    | ReLU       | 0      | train\n",
      "2 | sig_act   | Sigmoid    | 0      | train\n",
      "3 | encoder   | Sequential | 95.8 K | train\n",
      "4 | decoder   | Sequential | 96.6 K | train\n",
      "-------------------------------------------------\n",
      "192 K     Trainable params\n",
      "0         Non-trainable params\n",
      "192 K     Total params\n",
      "0.770     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a76daf2caac49b38ace3b6954a76376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833a3530f23d4b1b9af2dc42cf6a6ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04a514bb21b404a9d28a2000f6f7e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bffc203aaf14611b28d82e558bafcb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d4a5f2fb07408f9878456dfb6241da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e104db01a9433ea58fee6c5a7f6417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9d5ff76a4441da8f3ff1f65214a8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "symetric_dimensions = [784, 112, 56, 28]\n",
    "auto_encoder_model = AutoEncoderLinear(symetric_dimensions=symetric_dimensions, lr = 0.001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='valid_loss', mode='min', patience=5)\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "wandb_logger = WandbLogger(name = 'AutoEncoderLinear')\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs = 50,\n",
    "    accelerator = 'auto',\n",
    "    callbacks= [ early_stopping, lr_monitor],\n",
    "    logger = wandb_logger\n",
    ")\n",
    "\n",
    "trainer.fit(auto_encoder_model, \n",
    "            train_dataloader,\n",
    "            valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a96e773f6848e18e1e956541e1da8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0157100111246109     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0157100111246109    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 0.0157100111246109}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(auto_encoder_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEnocderClassifier(LightningModule):\n",
    "    def __init__(self, auto_encoder, num_classes = 10, lr = 0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lr = lr\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.acc = torchmetrics.Accuracy(task='multiclass', num_classes = num_classes)\n",
    "\n",
    "        self.auto_encoder = auto_encoder\n",
    "        self.fc = nn.Linear(28, num_classes)\n",
    "\n",
    "        self.batch_counter = 0\n",
    "        self.epoch_counter = 0\n",
    "        \n",
    "    def forward(self, x): \n",
    "        '''\n",
    "        INPUT\n",
    "            x : [batch_size, 1 , 28, 28]\n",
    "        OUTPUT\n",
    "            out : [batch_size, 10]\n",
    "        '''\n",
    "        latent = self.auto_encoder.predict_step(x) # [batch_size, 28]\n",
    "        out = self.fc(latent)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr= self.lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer = optimizer, step_size = 5, gamma = 0.5)\n",
    "        \n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.batch_counter += 1\n",
    "\n",
    "        if self.batch_counter % 32 == 0:\n",
    "            self.epoch_counter += 1\n",
    "\n",
    "        image, label =  batch\n",
    "\n",
    "        if label is None:\n",
    "            if self.epoch_counter % 3 == 0:\n",
    "                label = self.predict_step(batch)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        y_predict = self(image) # [batch_size, 10]\n",
    "\n",
    "        loss = self.criterion(y_predict, label)\n",
    "\n",
    "        _, pred = torch.max(y_predict, dim = 1)\n",
    "        acc = self.acc(pred, label)\n",
    "\n",
    "        self.log(\"train loss\", loss, on_step = True, on_epoch = True,  logger = True)\n",
    "        self.log(\"train Accuracy\", acc, on_step = True, on_epoch = True, logger = True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        image, label =  batch\n",
    "\n",
    "        y_predict = self(image) # [batch_size, 10]\n",
    "\n",
    "        loss = self.criterion(y_predict, label)\n",
    "\n",
    "        _, pred = torch.max(y_predict, dim = 1)\n",
    "        acc = self.acc(pred, label)\n",
    "\n",
    "        self.log(\"valid_loss\", loss, on_step = True, on_epoch = True,  logger = True)\n",
    "        self.log(\"valid_acc\", acc, on_step = True, on_epoch = True, logger = True)\n",
    "\n",
    "        return loss\n",
    "        \n",
    "    def test_step(self, batch):\n",
    "        image, label =  batch\n",
    "\n",
    "        y_predict = self(image) # [batch_size, 10]\n",
    "\n",
    "        loss = self.criterion(y_predict, label)\n",
    "\n",
    "        _, pred = torch.max(y_predict, dim = 1)\n",
    "        acc = self.acc(pred, label)\n",
    "\n",
    "        self.log(\"test loss\", loss, on_step = True, on_epoch = True,  logger = True)\n",
    "        self.log(\"test Accuracy\", acc, on_step = True, on_epoch = True, logger = True)\n",
    "\n",
    "        return acc\n",
    "\n",
    "    def predict_step(self, batch):\n",
    "        data, label = batch\n",
    "\n",
    "        y_predict = self(data) # [batch_size, 10]\n",
    "\n",
    "        _, pred = torch.max(y_predict, dim = 1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory ./lightning_logs/5m84csym/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name         | Type               | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | criterion    | CrossEntropyLoss   | 0      | train\n",
      "1 | acc          | MulticlassAccuracy | 0      | train\n",
      "2 | auto_encoder | AutoEncoderLinear  | 192 K  | eval \n",
      "3 | fc           | Linear             | 290    | train\n",
      "------------------------------------------------------------\n",
      "192 K     Trainable params\n",
      "0         Non-trainable params\n",
      "192 K     Total params\n",
      "0.771     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4e6e5399e643db9c0a7a68df3c7523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5034d3d5562e4fe0a440177c6f42fa32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e477d343a7d4c108423f77dd184ddd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69f4acaa4384082ad2645673ae9b0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0aee2f3d8dd455da4dd29b3e22ab625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9dc3426dd594b83bcf96a591aea7376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caca8b28723242fd87eeaffc72156af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788759d0879e4a9bb9aa03646f9e5fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2718af5d188c4697a60b80391a96331a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90300141ed04e00b741e160b9fb7ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c955ada3ebaf44fd9d182c4e87551dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c339c4a2d6b742748d45902faf078c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df14795cf4de46d896ceaf90260e9d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5379cf79482f43dc8c3ed2bf3905ee2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af15d4286454df4a57246e5e4491b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e717179fbfd4c348c70899f3c89af9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792f8287dcf04686a7ce134110a49689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cc4078d1654ab98e85c197e0492215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88677c562c844a8924f686f83f0ae05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abecaafc3f194b0c9be508aa63b7e7e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79654638c6eb4c6abedc81257da8ce34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ac960f41b24390821b87850667513d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8ba1f737334c0aa20c0aca559cde54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff4538cf55748b1afcf5afbed7eecb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69808eb32d8a44f78f8dd3c0f13b6f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb6574f375844cb866d4a388bb1ca39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52304098fe6841c5afe8e4707aa88f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7060aa07854ebb9e35be656a5edda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0f3547935240a8b6bcf189222ccc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b382b0e4a24943a5a10b1445dc6ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7197bb42c904f1aa4c69f5c51c61ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57cc7f182bf4d99af0bb215a37cd11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "auto_encoder_classifier = AutoEnocderClassifier(auto_encoder = auto_encoder_model)\n",
    "wandb_logger = WandbLogger(name = 'AutoEncoder Classifier')\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs = 30,\n",
    "    accelerator = 'auto',\n",
    "    callbacks = [lr_monitor],\n",
    "    logger = wandb_logger\n",
    ")\n",
    "\n",
    "trainer.fit(auto_encoder_classifier, shuffled_train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3e319690c3417b94c6ee1e3fdc18b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test Accuracy_epoch    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9638000726699829     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13764595985412598    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test Accuracy_epoch   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9638000726699829    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13764595985412598   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test loss_epoch': 0.13764595985412598,\n",
       "  'test Accuracy_epoch': 0.9638000726699829}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(auto_encoder_classifier, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
